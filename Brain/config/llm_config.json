{
    "default_provider": "groq",
    "calls": {
        "core_theme_extraction": {
            "provider": "openai",
            "model": "gpt-4.1",
            "temperature": 0.4,
            "max_tokens": 500
        },
        "age_adapter_13yo": {
            "provider": "openai",
            "model": "gpt-4.1",
            "temperature": 0.4,
            "max_tokens": 500
        },
        "exploration_directions_evaluation": {
            "provider": "openai",
            "model": "gpt-4.1",
            "temperature": 0.4,
            "max_tokens": 500
        },
        "chat_controller": {
            "provider": "openai",
            "model": "gpt-4o",
            "temperature": 0.7,
            "max_tokens": 1000
          },
        "homework_updater": {
            "provider": "openai",
            "model": "gpt-4.1",
            "temperature": 0.2,
            "max_tokens": 800,
            "json_mode": true
            },
        "knowledge_updater": {
            "provider": "openai",
            "model": "gpt-4.1",
            "temperature": 0.2,
            "max_tokens": 800
            },
        "intent_identification": {
            "provider": "groq",
            "model": "llama-3.3-70b-versatile",
            "temperature": 0.3,
            "max_tokens": 500
        },
        "response_generation": {
            "provider": "openai",
            "model": "gpt-4.1",
            "temperature": 0.7,
            "max_tokens": 4096
        },
        "simplified_conversation": {
            "provider": "openai",
            "model": "gpt-4.1",
            "temperature": 0.4,
            "max_tokens": 1000
          },
        "knowledge_retrieval": {
            "provider": "openai",
            "model": "gpt-4o",
            "temperature": 0.2,
            "max_tokens": 500
        },
        "learning_enhancement": {
            "provider": "openai",
            "model": "gpt-4o",
            "temperature": 0.8,
            "max_tokens": 1000
        },
        "user_persona_generation": {
            "provider": "openai",
            "model": "gpt-4.1",
            "temperature": 0.5,
            "max_tokens": 4096
        },
        "opening_message": {
            "provider": "openai",
            "model": "gpt-4.1",
            "temperature": 0.3,
            "max_tokens": 1000
        },
        "memory_generation": {
            "provider": "openai",
            "model": "gpt-4.1",
            "temperature": 0.5,
            "max_tokens": 4096
        }
    },
    "providers": {
        "openai": {
            "api_key_env": "OPENAI_API_KEY"
        },
        "groq": {
            "api_key_env": "GROQ_API_KEY"
        }
    }
} 

