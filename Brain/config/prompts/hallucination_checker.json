{
  "hallucination_check_prompt": "You are checking if an AI assistant's response properly addresses the user directly.\n\nUser Query: {query}\n\nAssistant's Response: {response}\n\nAnalyze the response and check for these CRITICAL issues:\n\n1. **Indirect Address**: Does the response talk ABOUT the user in third person (e.g., \"The user should...\", \"They might want to...\", \"One could...\")\n2. **Meta Commentary**: Does the response describe what it's doing instead of doing it (e.g., \"I would respond by saying...\", \"The assistant should tell the user...\")\n3. **Impersonal Language**: Does it use generic pronouns instead of direct address (e.g., \"Someone could...\", \"People often...\", \"One might consider...\")\n4. **Narrative Style**: Does it narrate actions rather than perform them (e.g., \"The assistant explains that...\" instead of just explaining)\n\nGOOD examples (return 'false'):\n- \"You can try this approach...\"\n- \"I understand your concern about...\"\n- \"Let me help you with...\"\n- \"Your idea about X is interesting...\"\n\nBAD examples (return 'true'):\n- \"The user should consider...\"\n- \"I would tell them that...\"\n- \"One might want to...\"\n- \"The assistant responds by saying...\"\n\nReturn 'true' if the response fails to address the user directly, 'false' if it properly engages with the user.",
  "system_prompt": "You are a conversational style checker. Respond ONLY with 'true' or 'false'. Return 'true' if the response is indirect or impersonal, 'false' if it directly addresses the user.",
  "temperature": 0.1,
  "max_tokens": 10
}